from __future__ import annotations

from typing import Dict, Any, Tuple, List, Callable
import os
import logging
import inspect

from .classifier import classify_platform

from ..extractors.generic import extract_generic
from ..extractors.shopee import extract_shopee
from ..extractors.lazada import extract_lazada
from ..extractors.tiktok import extract_tiktok

# ‚úÖ spx optional
try:
    from ..extractors.spx import extract_spx  # type: ignore
except Exception:  # pragma: no cover
    extract_spx = None  # type: ignore

from ..utils.validators import (
    validate_yyyymmdd,
    validate_branch5,
    validate_tax13,
    validate_price_type,
    validate_vat_rate,
)

from .ai_extract_service import extract_with_ai

logger = logging.getLogger(__name__)

# ============================================================
# üî• PEAK columns lock (A-U) ‚Äî ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏≠‡∏µ‡∏Å
# ============================================================
PEAK_KEYS_ORDER: List[str] = [
    "A_seq",
    "B_doc_date",
    "C_reference",
    "D_vendor_code",
    "E_tax_id_13",
    "F_branch_5",
    "G_invoice_no",
    "H_invoice_date",
    "I_tax_purchase_date",
    "J_price_type",
    "K_account",
    "L_description",
    "M_qty",
    "N_unit_price",
    "O_vat_rate",
    "P_wht",
    "Q_payment_method",
    "R_paid_amount",
    "S_pnd",
    "T_note",
    "U_group",
]

# ‡∏Å‡∏±‡∏ô AI / extractor ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡∏ö key ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ ‚Äú‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ä‡πà‡∏≠‡∏á‚Äù
_AI_BLACKLIST_KEYS = {"T_note", "U_group", "K_account"}

# ‡∏Ñ‡∏µ‡∏¢‡πå‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ (metadata)
_INTERNAL_OK_PREFIXES = ("_",)

# ============================================================
# helpers: safe merge + sanitize
# ============================================================

def _sanitize_incoming_row(d: Any) -> Dict[str, Any]:
    """‡∏£‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ dict ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"""
    return d if isinstance(d, dict) else {}


def _sanitize_ai_row(ai: Dict[str, Any]) -> Dict[str, Any]:
    """
    - ‡∏ï‡∏±‡∏î key ‡∏ï‡πâ‡∏≠‡∏á‡∏´‡πâ‡∏≤‡∏°: T_note, U_group, K_account
    - ‡∏ï‡∏±‡∏î None/"" ‡∏≠‡∏≠‡∏Å
    - ‡∏£‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ key ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô PEAK A-U ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô _meta
    """
    if not ai:
        return {}

    cleaned: Dict[str, Any] = {}
    for k, v in ai.items():
        if not k:
            continue
        if k in _AI_BLACKLIST_KEYS:
            continue
        if v in ("", None):
            continue

        # allow PEAK keys
        if k in PEAK_KEYS_ORDER:
            cleaned[k] = v
            continue

        # allow internal meta keys
        if k.startswith(_INTERNAL_OK_PREFIXES):
            cleaned[k] = v
            continue

        # ignore everything else to prevent column shift / garbage keys
        # e.g. "account", "group", "platform" etc
        continue

    return cleaned


def _merge_rows(
    base: Dict[str, Any],
    patch: Dict[str, Any],
    *,
    fill_missing: bool = True,
) -> Dict[str, Any]:
    """
    merge patch into base:
    - fill_missing=True  -> ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á / 0 / 0.00
    - fill_missing=False -> ‡∏ó‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ key ‡∏ó‡∏µ‡πà patch ‡∏™‡πà‡∏á‡∏°‡∏≤ (‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏ó‡∏±‡∏ö blacklist)
    """
    if not patch:
        return base

    out = dict(base)

    for k, v in patch.items():
        if not k:
            continue
        if k in _AI_BLACKLIST_KEYS:
            continue
        if v in ("", None):
            continue

        if fill_missing:
            cur = out.get(k, "")
            if cur in ("", None, "0", "0.00"):
                out[k] = v
        else:
            out[k] = v

    return out


# ============================================================
# helpers: validation
# ============================================================

def _validate_row(row: Dict[str, Any]) -> List[str]:
    errors: List[str] = []

    if not validate_yyyymmdd(row.get("B_doc_date", "")):
        errors.append("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    if row.get("H_invoice_date") and not validate_yyyymmdd(row.get("H_invoice_date", "")):
        errors.append("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ö‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏Ø‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    if row.get("I_tax_purchase_date") and not validate_yyyymmdd(row.get("I_tax_purchase_date", "")):
        errors.append("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏†‡∏≤‡∏©‡∏µ‡∏ã‡∏∑‡πâ‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    if row.get("F_branch_5") and not validate_branch5(row.get("F_branch_5", "")):
        errors.append("‡πÄ‡∏•‡∏Ç‡∏™‡∏≤‡∏Ç‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 5 ‡∏´‡∏•‡∏±‡∏Å")

    if row.get("E_tax_id_13") and not validate_tax13(row.get("E_tax_id_13", "")):
        errors.append("‡πÄ‡∏•‡∏Ç‡∏†‡∏≤‡∏©‡∏µ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 13 ‡∏´‡∏•‡∏±‡∏Å")

    if not validate_price_type(row.get("J_price_type", "")):
        errors.append("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏≤‡∏Ñ‡∏≤‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    if not validate_vat_rate(row.get("O_vat_rate", "")):
        errors.append("‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏†‡∏≤‡∏©‡∏µ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    return errors


# ============================================================
# helpers: extractor call (backward compatible)
# ============================================================

def _safe_call_extractor(
    fn: Callable[..., Dict[str, Any]],
    text: str,
    *,
    filename: str = "",
    client_tax_id: str = "",
) -> Dict[str, Any]:
    """
    ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å extractor ‡πÅ‡∏ö‡∏ö backward-compatible:
    - ‡∏ñ‡πâ‡∏≤‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö filename/client_tax_id -> ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ
    - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö -> fallback fn(text)
    """
    try:
        sig = inspect.signature(fn)
        params = sig.parameters

        kwargs: Dict[str, Any] = {}
        if "filename" in params:
            kwargs["filename"] = filename
        if "client_tax_id" in params and client_tax_id:
            kwargs["client_tax_id"] = client_tax_id

        if kwargs:
            return fn(text, **kwargs)  # type: ignore[arg-type]
    except Exception:
        pass

    # fallback tries
    if client_tax_id:
        try:
            return fn(text, client_tax_id=client_tax_id)  # type: ignore
        except TypeError:
            pass

    return fn(text)  # type: ignore


# ============================================================
# üî• FINAL LOCK: force PEAK schema + fix Marketplace group
# ============================================================

def lock_peak_columns(row: Dict[str, Any]) -> Dict[str, Any]:
    """
    1) ‡∏•‡πá‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡∏°‡∏µ‡πÅ‡∏ï‡πà‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå PEAK A-U + _meta
    2) ‡πÉ‡∏™‡πà‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤ "" (‡∏Å‡∏±‡∏ô CSV/Excel ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô)
    3) ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏≠‡∏≤ key ‡πÅ‡∏õ‡∏•‡∏Å ‡πÜ ‡∏°‡∏≤‡∏õ‡∏ô
    """
    safe = _sanitize_incoming_row(row)

    out: Dict[str, Any] = {}

    # Keep internal meta first
    for k, v in safe.items():
        if isinstance(k, str) and k.startswith(_INTERNAL_OK_PREFIXES):
            out[k] = v

    # Lock PEAK keys
    for k in PEAK_KEYS_ORDER:
        out[k] = safe.get(k, "")

    return out


def enforce_marketplace_group(row: Dict[str, Any], platform: str) -> Dict[str, Any]:
    """
    ‚úÖ ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î:
    - U_group ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô Marketplace Expense ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö marketplace docs
    - ‡∏´‡πâ‡∏≤‡∏°‡πÑ‡∏õ‡∏≠‡∏¢‡∏π‡πà K_account
    """
    p = (platform or "").lower().strip()
    desc = str(row.get("L_description", "") or "").strip()

    is_marketplace = p in ("shopee", "lazada", "tiktok", "spx") or (desc == "Marketplace Expense")
    if is_marketplace:
        row["U_group"] = "Marketplace Expense"

        # ‡∏Å‡∏±‡∏ô case ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô: Marketplace Expense ‡πÑ‡∏õ‡∏≠‡∏¢‡∏π‡πà K_account
        if str(row.get("K_account", "") or "").strip() == "Marketplace Expense":
            row["K_account"] = ""

    return row


def _finalize_row(row: Dict[str, Any], platform: str) -> Dict[str, Any]:
    """
    Final sanitize:
    - T_note ‡∏ß‡πà‡∏≤‡∏á
    - sync C/G
    - force U_group rule
    - lock schema
    """
    # ‚úÖ notes must be empty
    if os.getenv("FORCE_EMPTY_NOTE", "1") == "1":
        row["T_note"] = ""

    # ‚úÖ sync references
    if not row.get("C_reference") and row.get("G_invoice_no"):
        row["C_reference"] = row.get("G_invoice_no", "")
    if not row.get("G_invoice_no") and row.get("C_reference"):
        row["G_invoice_no"] = row.get("C_reference", "")

    # ‚úÖ enforce marketplace group last
    row = enforce_marketplace_group(row, platform)

    # ‚úÖ lock columns last (‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô)
    row = lock_peak_columns(row)

    return row


def _record_ai_error(row: Dict[str, Any], stage: str, exc: Exception) -> None:
    if os.getenv("STORE_AI_ERROR_META", "1") != "1":
        return
    msg = f"{stage}: {type(exc).__name__}: {str(exc)}"
    msg = msg[:500]
    arr = row.get("_ai_errors")
    if not isinstance(arr, list):
        arr = []
    arr.append(msg)
    row["_ai_errors"] = arr


# ============================================================
# üî• MAIN ENTRY
# ============================================================

def extract_row_from_text(
    text: str,
    filename: str = "",
    client_tax_id: str = "",
) -> Tuple[str, Dict[str, Any], List[str]]:
    """
    return: platform, row, errors
    """

    # 1) classify
    try:
        platform = classify_platform(text)
    except Exception as e:
        logger.exception("classify_platform failed: %s", e)
        platform = "generic"

    # 2) extractor baseline
    try:
        if platform == "shopee":
            row = _safe_call_extractor(extract_shopee, text, filename=filename, client_tax_id=client_tax_id)
        elif platform == "lazada":
            row = _safe_call_extractor(extract_lazada, text, filename=filename, client_tax_id=client_tax_id)
        elif platform == "tiktok":
            row = _safe_call_extractor(extract_tiktok, text, filename=filename, client_tax_id=client_tax_id)
        elif platform == "spx" and extract_spx is not None:
            row = _safe_call_extractor(extract_spx, text, filename=filename, client_tax_id=client_tax_id)
        else:
            row = _safe_call_extractor(extract_generic, text, filename=filename, client_tax_id=client_tax_id)
    except Exception as e:
        logger.exception("Extractor error (platform=%s, file=%s)", platform, filename)
        row = extract_generic(text)
        row["_extractor_error"] = f"{type(e).__name__}: {str(e)}"[:500]

    row = _sanitize_incoming_row(row)

    # 3) AI ENHANCEMENT (SAFE + blacklist + key filter)
    if os.getenv("ENABLE_AI_EXTRACT", "0") == "1":
        try:
            # ‚úÖ ‡∏™‡πà‡∏á client_tax_id ‡πÉ‡∏´‡πâ AI ‡∏ñ‡πâ‡∏≤ service ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö/‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡πá‡πÑ‡∏°‡πà‡∏•‡πà‡∏°)
            try:
                ai_raw = extract_with_ai(text, filename=filename, client_tax_id=client_tax_id)
            except TypeError:
                ai_raw = extract_with_ai(text, filename=filename)

            ai_row = _sanitize_ai_row(_sanitize_incoming_row(ai_raw))
            fill_missing = os.getenv("AI_FILL_MISSING", "1") == "1"
            row = _merge_rows(row, ai_row, fill_missing=fill_missing)
        except Exception as e:
            logger.warning("AI extract failed (file=%s): %s", filename, e)
            _record_ai_error(row, "ai_extract", e)

    # 4) validate
    errors = _validate_row(row)

    # 5) AI REPAIR PASS (SAFE + blacklist + key filter)
    if errors and os.getenv("AI_REPAIR_PASS", "0") == "1":
        try:
            prompt = text + "\n\n# VALIDATION_ERRORS\n" + "\n".join(errors)
            try:
                ai_fix_raw = extract_with_ai(prompt, filename=filename, client_tax_id=client_tax_id)
            except TypeError:
                ai_fix_raw = extract_with_ai(prompt, filename=filename)

            ai_fix = _sanitize_ai_row(_sanitize_incoming_row(ai_fix_raw))

            # repair pass = allow overwrite but still respect blacklist
            row = _merge_rows(row, ai_fix, fill_missing=False)

            errors = _validate_row(row)
        except Exception as e:
            logger.warning("AI repair failed (file=%s): %s", filename, e)
            _record_ai_error(row, "ai_repair", e)

    # 6) FINALIZE (üî• ‡∏à‡∏∏‡∏î‡∏Å‡∏±‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô)
    row = _finalize_row(row, platform)

    return platform, row, errors
