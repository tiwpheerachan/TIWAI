from __future__ import annotations

from typing import Dict, Any, Tuple, List, Callable, Optional
import os
import logging
import inspect
import re

from .classifier import classify_platform

from ..extractors.generic import extract_generic
from ..extractors.shopee import extract_shopee
from ..extractors.lazada import extract_lazada
from ..extractors.tiktok import extract_tiktok

# ‚úÖ spx optional
try:
    from ..extractors.spx import extract_spx  # type: ignore
except Exception:  # pragma: no cover
    extract_spx = None  # type: ignore

# ‚úÖ vendor code mapping (Cxxxxx)
try:
    from ..extractors.vendor_mapping import get_vendor_code, detect_client_from_context
    _VENDOR_MAPPING_OK = True
except Exception:  # pragma: no cover
    get_vendor_code = None  # type: ignore
    detect_client_from_context = None  # type: ignore
    _VENDOR_MAPPING_OK = False

from ..utils.validators import (
    validate_yyyymmdd,
    validate_branch5,
    validate_tax13,
    validate_price_type,
    validate_vat_rate,
)

# ‚úÖ AI extractor (optional)
try:
    from .ai_extract_service import extract_with_ai
    _AI_OK = True
except Exception:  # pragma: no cover
    extract_with_ai = None  # type: ignore
    _AI_OK = False

logger = logging.getLogger(__name__)

# ============================================================
# üî• PEAK columns lock (A-U) ‚Äî ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏≠‡∏µ‡∏Å
# ============================================================
PEAK_KEYS_ORDER: List[str] = [
    "A_seq",
    "A_company_name",
    "B_doc_date",
    "C_reference",
    "D_vendor_code",
    "E_tax_id_13",
    "F_branch_5",
    "G_invoice_no",
    "H_invoice_date",
    "I_tax_purchase_date",
    "J_price_type",
    "K_account",
    "L_description",
    "M_qty",
    "N_unit_price",
    "O_vat_rate",
    "P_wht",
    "Q_payment_method",
    "R_paid_amount",
    "S_pnd",
    "T_note",
    "U_group",
]

# ‡∏Å‡∏±‡∏ô AI / extractor ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡∏ö key ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ "‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ä‡πà‡∏≠‡∏á"
_AI_BLACKLIST_KEYS = {"T_note", "U_group", "K_account"}

# ‡∏Ñ‡∏µ‡∏¢‡πå‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ (metadata)
_INTERNAL_OK_PREFIXES = ("_",)

# ‚úÖ whitespace compact for ref/invoice
_RE_ALL_WS = re.compile(r"\s+")

# ============================================================
# helpers: safe merge + sanitize
# ============================================================

def _sanitize_incoming_row(d: Any) -> Dict[str, Any]:
    """‡∏£‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ dict ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"""
    return d if isinstance(d, dict) else {}

def _compact_no_ws(v: Any) -> str:
    """
    ‚úÖ ‡∏ï‡∏±‡∏î whitespace ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (space/newline/tab) ‡πÉ‡∏´‡πâ token ‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô
    ‡πÄ‡∏ä‡πà‡∏ô "RCSPX...-25 1218-0001" -> "RCSPX...-251218-0001"
    """
    s = "" if v is None else str(v)
    s = s.strip()
    if not s:
        return ""
    return _RE_ALL_WS.sub("", s)

def _sanitize_ai_row(ai: Dict[str, Any]) -> Dict[str, Any]:
    """
    - ‡∏ï‡∏±‡∏î key ‡∏ï‡πâ‡∏≠‡∏á‡∏´‡πâ‡∏≤‡∏°: T_note, U_group, K_account
    - ‡∏ï‡∏±‡∏î None/"" ‡∏≠‡∏≠‡∏Å
    - ‡∏£‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ key ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô PEAK_KEYS_ORDER ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô _meta
    """
    if not ai:
        return {}

    cleaned: Dict[str, Any] = {}
    for k, v in ai.items():
        if not k:
            continue
        if k in _AI_BLACKLIST_KEYS:
            continue
        if v in ("", None):
            continue

        if k in PEAK_KEYS_ORDER:
            cleaned[k] = v
            continue

        if isinstance(k, str) and k.startswith(_INTERNAL_OK_PREFIXES):
            cleaned[k] = v
            continue

    return cleaned

def _merge_rows(
    base: Dict[str, Any],
    patch: Dict[str, Any],
    *,
    fill_missing: bool = True,
) -> Dict[str, Any]:
    """
    merge patch into base:
    - fill_missing=True  -> ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á / 0 / 0.00
    - fill_missing=False -> ‡∏ó‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ key ‡∏ó‡∏µ‡πà patch ‡∏™‡πà‡∏á‡∏°‡∏≤ (‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏ó‡∏±‡∏ö blacklist)
    """
    if not patch:
        return base

    out = dict(base)

    for k, v in patch.items():
        if not k:
            continue
        if k in _AI_BLACKLIST_KEYS:
            continue
        if v in ("", None):
            continue

        if fill_missing:
            cur = out.get(k, "")
            if cur in ("", None, "0", "0.00"):
                out[k] = v
        else:
            out[k] = v

    return out

# ============================================================
# helpers: validation
# ============================================================

def _validate_row(row: Dict[str, Any]) -> List[str]:
    errors: List[str] = []

    if not validate_yyyymmdd(row.get("B_doc_date", "")):
        errors.append("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    if row.get("H_invoice_date") and not validate_yyyymmdd(row.get("H_invoice_date", "")):
        errors.append("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ö‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏Ø‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    if row.get("I_tax_purchase_date") and not validate_yyyymmdd(row.get("I_tax_purchase_date", "")):
        errors.append("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏†‡∏≤‡∏©‡∏µ‡∏ã‡∏∑‡πâ‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    if row.get("F_branch_5") and not validate_branch5(row.get("F_branch_5", "")):
        errors.append("‡πÄ‡∏•‡∏Ç‡∏™‡∏≤‡∏Ç‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 5 ‡∏´‡∏•‡∏±‡∏Å")

    if row.get("E_tax_id_13") and not validate_tax13(row.get("E_tax_id_13", "")):
        errors.append("‡πÄ‡∏•‡∏Ç‡∏†‡∏≤‡∏©‡∏µ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 13 ‡∏´‡∏•‡∏±‡∏Å")

    if not validate_price_type(row.get("J_price_type", "")):
        errors.append("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏≤‡∏Ñ‡∏≤‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    if not validate_vat_rate(row.get("O_vat_rate", "")):
        errors.append("‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏†‡∏≤‡∏©‡∏µ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    return errors

# ============================================================
# helpers: extractor call (backward compatible)
# ============================================================

def _safe_call_extractor(
    fn: Callable[..., Dict[str, Any]],
    text: str,
    *,
    filename: str = "",
    client_tax_id: str = "",
    cfg: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    """
    ‚úÖ FIX: ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å extractor ‡πÅ‡∏ö‡∏ö backward-compatible + ‡πÄ‡∏û‡∏¥‡πà‡∏° cfg support
    
    - ‡∏ñ‡πâ‡∏≤‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö filename/client_tax_id/cfg -> ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ
    - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö -> fallback fn(text)
    """
    try:
        sig = inspect.signature(fn)
        params = sig.parameters

        kwargs: Dict[str, Any] = {}
        if "filename" in params:
            kwargs["filename"] = filename
        if "client_tax_id" in params and client_tax_id:
            kwargs["client_tax_id"] = client_tax_id
        if "cfg" in params and cfg:  # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° cfg support
            kwargs["cfg"] = cfg

        if kwargs:
            return fn(text, **kwargs)  # type: ignore[arg-type]
    except Exception:
        pass

    # Fallback attempts (backward compatibility)
    if client_tax_id:
        try:
            return fn(text, client_tax_id=client_tax_id)  # type: ignore
        except TypeError:
            pass

    return fn(text)  # type: ignore

# ============================================================
# ‚úÖ Vendor code mapping pass (force D_vendor_code = Cxxxxx)
# ============================================================

def _apply_vendor_code_mapping(row: Dict[str, Any], text: str, client_tax_id: str) -> Dict[str, Any]:
    """
    Force D_vendor_code to be Cxxxxx using vendor_mapping.py
    """
    if not isinstance(row, dict):
        return row

    if not _VENDOR_MAPPING_OK or get_vendor_code is None:
        return row

    ctax = (client_tax_id or "").strip()
    if not ctax and detect_client_from_context is not None:
        try:
            ctax = detect_client_from_context(text) or ""
        except Exception:
            ctax = ""

    if not ctax:
        return row

    vtax = str(row.get("E_tax_id_13") or "").strip()
    vname = str(row.get("D_vendor_code") or "").strip()

    try:
        code = get_vendor_code(client_tax_id=ctax, vendor_tax_id=vtax, vendor_name=vname)
    except Exception:
        return row

    if isinstance(code, str) and code.startswith("C") and len(code) >= 5:
        row["D_vendor_code"] = code
        if os.getenv("STORE_VENDOR_MAPPING_META", "1") == "1":
            row["_client_tax_id_used"] = ctax
            row["_vendor_tax_id_used"] = vtax or ""
            row["_vendor_code_resolved"] = code

    return row

# ============================================================
# üî• FINAL LOCK: force PEAK schema + fix Marketplace group
# ============================================================

def lock_peak_columns(row: Dict[str, Any]) -> Dict[str, Any]:
    """
    1) ‡∏•‡πá‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡∏°‡∏µ‡πÅ‡∏ï‡πà‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå PEAK + _meta
    2) ‡πÉ‡∏™‡πà‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤ "" (‡∏Å‡∏±‡∏ô CSV/Excel ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô)
    3) ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏≠‡∏≤ key ‡πÅ‡∏õ‡∏•‡∏Å ‡πÜ ‡∏°‡∏≤‡∏õ‡∏ô
    """
    safe = _sanitize_incoming_row(row)
    out: Dict[str, Any] = {}

    # Keep internal meta first
    for k, v in safe.items():
        if isinstance(k, str) and k.startswith(_INTERNAL_OK_PREFIXES):
            out[k] = v

    # Lock PEAK keys
    for k in PEAK_KEYS_ORDER:
        out[k] = safe.get(k, "")

    return out

def enforce_marketplace_group(row: Dict[str, Any], platform: str) -> Dict[str, Any]:
    """
    ‚úÖ ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î:
    - U_group ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô Marketplace Expense ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö marketplace docs
    - ‡∏´‡πâ‡∏≤‡∏°‡πÑ‡∏õ‡∏≠‡∏¢‡∏π‡πà K_account
    """
    p = (platform or "").lower().strip()
    desc = str(row.get("L_description", "") or "").strip()

    is_marketplace = p in ("shopee", "lazada", "tiktok", "spx") or (desc == "Marketplace Expense")
    if is_marketplace:
        row["U_group"] = "Marketplace Expense"
        if str(row.get("K_account", "") or "").strip() == "Marketplace Expense":
            row["K_account"] = ""

    return row

def _finalize_row(row: Dict[str, Any], platform: str) -> Dict[str, Any]:
    """
    Final sanitize:
    - P_wht ‡∏ß‡πà‡∏≤‡∏á (‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å)
    - T_note ‡∏ß‡πà‡∏≤‡∏á
    - sync C/G + compact no whitespace
    - force U_group rule
    - lock schema
    """
    # ‚úÖ WHT must be empty (your export requirement)
    row["P_wht"] = ""

    # ‚úÖ notes must be empty
    if os.getenv("FORCE_EMPTY_NOTE", "1") == "1":
        row["T_note"] = ""

    # ‚úÖ sync references
    if not row.get("C_reference") and row.get("G_invoice_no"):
        row["C_reference"] = row.get("G_invoice_no", "")
    if not row.get("G_invoice_no") and row.get("C_reference"):
        row["G_invoice_no"] = row.get("C_reference", "")

    # ‚úÖ compact reference / invoice
    row["C_reference"] = _compact_no_ws(row.get("C_reference", ""))
    row["G_invoice_no"] = _compact_no_ws(row.get("G_invoice_no", ""))

    # ‚úÖ enforce marketplace group last
    row = enforce_marketplace_group(row, platform)

    # ‚úÖ lock columns last (‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô)
    row = lock_peak_columns(row)

    return row

def _record_ai_error(row: Dict[str, Any], stage: str, exc: Exception) -> None:
    if os.getenv("STORE_AI_ERROR_META", "1") != "1":
        return
    msg = f"{stage}: {type(exc).__name__}: {str(exc)}"
    msg = msg[:500]
    arr = row.get("_ai_errors")
    if not isinstance(arr, list):
        arr = []
    arr.append(msg)
    row["_ai_errors"] = arr

# ============================================================
# üî• MAIN ENTRY
# ============================================================

def extract_row_from_text(
    text: str,
    filename: str = "",
    client_tax_id: str = "",
    cfg: Optional[Dict[str, Any]] = None,  # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° cfg parameter
) -> Tuple[str, Dict[str, Any], List[str]]:
    """
    ‚úÖ FIX: ‡πÄ‡∏û‡∏¥‡πà‡∏° cfg parameter ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö job_worker_fixed.py
    
    Args:
        text: Document text
        filename: Filename for hints
        client_tax_id: Client tax ID (if known)
        cfg: Job config (optional, contains client_tags/platforms/strictMode)
    
    Returns:
        (platform, row, errors)
    """

    # 0) normalize inputs (safe)
    text = text or ""
    filename = filename or ""
    client_tax_id = (client_tax_id or "").strip()
    cfg = cfg or {}

    # 1) classify (‚úÖ MUST pass filename + cfg for better hints)
    try:
        # ‚úÖ Try to pass cfg to classifier if it supports it
        try:
            sig = inspect.signature(classify_platform)
            if "cfg" in sig.parameters:
                platform = classify_platform(text, filename=filename, cfg=cfg)
            else:
                platform = classify_platform(text, filename=filename)
        except Exception:
            platform = classify_platform(text, filename=filename)
    except Exception as e:
        logger.exception("classify_platform failed: %s", e)
        platform = "unknown"

    # 1.1) normalize platform label (defensive)
    # classifier returns: shopee/lazada/tiktok/spx/ads/other/unknown
    # we route "other/unknown" -> generic extractor
    if platform not in ("shopee", "lazada", "tiktok", "spx", "ads", "other", "unknown"):
        platform = "unknown"

    # 2) extractor baseline
    try:
        if platform == "shopee":
            row = _safe_call_extractor(extract_shopee, text, filename=filename, client_tax_id=client_tax_id, cfg=cfg)
        elif platform == "lazada":
            row = _safe_call_extractor(extract_lazada, text, filename=filename, client_tax_id=client_tax_id, cfg=cfg)
        elif platform == "tiktok":
            row = _safe_call_extractor(extract_tiktok, text, filename=filename, client_tax_id=client_tax_id, cfg=cfg)
        elif platform == "spx":
            if extract_spx is not None:
                row = _safe_call_extractor(extract_spx, text, filename=filename, client_tax_id=client_tax_id, cfg=cfg)
            else:
                # if spx extractor missing, fallback to generic but keep meta
                row = _safe_call_extractor(extract_generic, text, filename=filename, client_tax_id=client_tax_id, cfg=cfg)
                row["_missing_extractor"] = "spx"
        else:
            # ads/other/unknown -> generic
            row = _safe_call_extractor(extract_generic, text, filename=filename, client_tax_id=client_tax_id, cfg=cfg)
    except Exception as e:
        logger.exception("Extractor error (platform=%s, file=%s)", platform, filename)
        row = _sanitize_incoming_row(extract_generic(text))
        row["_extractor_error"] = f"{type(e).__name__}: {str(e)}"[:500]

    row = _sanitize_incoming_row(row)

    # 2.1) ensure minimal stable defaults BEFORE AI/validate (‡∏•‡∏î error noise)
    row.setdefault("A_seq", "")
    row.setdefault("A_company_name", "")
    row.setdefault("J_price_type", row.get("J_price_type") or "1")
    row.setdefault("M_qty", row.get("M_qty") or "1")
    row.setdefault("O_vat_rate", row.get("O_vat_rate") or "7%")
    row.setdefault("L_description", row.get("L_description") or ("Marketplace Expense" if platform in ("shopee", "lazada", "tiktok", "spx") else ""))
    row.setdefault("U_group", row.get("U_group") or ("Marketplace Expense" if platform in ("shopee", "lazada", "tiktok", "spx") else ""))

    # store meta for debug (optional)
    if os.getenv("STORE_CLASSIFIER_META", "1") == "1":
        row["_platform"] = platform
        row["_filename"] = filename
        if cfg:  # ‚úÖ ‡πÄ‡∏Å‡πá‡∏ö cfg meta
            row["_cfg"] = str(cfg)[:200]

    # 3) AI ENHANCEMENT (optional + must be safe)
    if _AI_OK and extract_with_ai is not None and os.getenv("ENABLE_AI_EXTRACT", "0") == "1":
        try:
            # attempt with client_tax_id if supported
            try:
                ai_raw = extract_with_ai(text, filename=filename, client_tax_id=client_tax_id)
            except TypeError:
                ai_raw = extract_with_ai(text, filename=filename)

            ai_row = _sanitize_ai_row(_sanitize_incoming_row(ai_raw))
            fill_missing = os.getenv("AI_FILL_MISSING", "1") == "1"
            row = _merge_rows(row, ai_row, fill_missing=fill_missing)
        except Exception as e:
            logger.warning("AI extract failed (file=%s): %s", filename, e)
            _record_ai_error(row, "ai_extract", e)

    # 4) validate
    errors = _validate_row(row)

    # 5) AI REPAIR PASS (optional)
    if errors and _AI_OK and extract_with_ai is not None and os.getenv("AI_REPAIR_PASS", "0") == "1":
        try:
            prompt = (text or "") + "\n\n# VALIDATION_ERRORS\n" + "\n".join(errors)
            try:
                ai_fix_raw = extract_with_ai(prompt, filename=filename, client_tax_id=client_tax_id)
            except TypeError:
                ai_fix_raw = extract_with_ai(prompt, filename=filename)

            ai_fix = _sanitize_ai_row(_sanitize_incoming_row(ai_fix_raw))
            row = _merge_rows(row, ai_fix, fill_missing=False)
            errors = _validate_row(row)
        except Exception as e:
            logger.warning("AI repair failed (file=%s): %s", filename, e)
            _record_ai_error(row, "ai_repair", e)

    # 6) ‚úÖ Vendor code mapping pass (‡∏Å‡πà‡∏≠‡∏ô finalize/lock)
    row = _apply_vendor_code_mapping(row, text, client_tax_id)

    # 7) FINALIZE (‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô + compact + P_wht empty)
    row = _finalize_row(row, platform)

    return platform, row, errors